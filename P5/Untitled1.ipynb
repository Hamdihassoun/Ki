{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ed4323-7add-4ad3-a745-92b0b64d0c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.7160 - loss: 0.9071 - val_accuracy: 0.9580 - val_loss: 0.1457\n",
      "Epoch 2/50\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9442 - loss: 0.1817 - val_accuracy: 0.9826 - val_loss: 0.0572\n",
      "Epoch 3/50\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9576 - loss: 0.1465 - val_accuracy: 0.9840 - val_loss: 0.0543\n",
      "Epoch 4/50\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9660 - loss: 0.1150 - val_accuracy: 0.9877 - val_loss: 0.0403\n",
      "Epoch 5/50\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9679 - loss: 0.1056 - val_accuracy: 0.9869 - val_loss: 0.0440\n",
      "Epoch 6/50\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9720 - loss: 0.0938 - val_accuracy: 0.9901 - val_loss: 0.0308\n",
      "Epoch 7/50\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9734 - loss: 0.0865 - val_accuracy: 0.9912 - val_loss: 0.0266\n",
      "Epoch 8/50\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9752 - loss: 0.0855 - val_accuracy: 0.9911 - val_loss: 0.0272\n",
      "Epoch 9/50\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9762 - loss: 0.0811 - val_accuracy: 0.9904 - val_loss: 0.0321\n",
      "Epoch 10/50\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9775 - loss: 0.0813 - val_accuracy: 0.9885 - val_loss: 0.0440\n",
      "Epoch 11/50\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9791 - loss: 0.0761 - val_accuracy: 0.9892 - val_loss: 0.0333\n",
      "Epoch 12/50\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9793 - loss: 0.0737 - val_accuracy: 0.9893 - val_loss: 0.0363\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Daten laden\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# Trainingsdaten aufteilen\n",
    "X = train_data.iloc[:, 1:].values  # Pixelwerte\n",
    "y = train_data.iloc[:, 0].values   # Labels\n",
    "\n",
    "# Normalisierung der Pixelwerte\n",
    "X = X / 255.0\n",
    "X_test = test_data.values / 255.0\n",
    "\n",
    "# Reshape für CNN (28x28 Bilder mit 1 Kanal)\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Labels in One-Hot-Encoding umwandeln\n",
    "y = to_categorical(y, num_classes=10)\n",
    "\n",
    "# Daten aufteilen in Training und Validierung\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Datenaugmentation vorbereiten\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# CNN-Modell erstellen\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping, um Overfitting zu vermeiden\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Modell trainieren mit Datenaugmentation\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=50,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Vorhersagen für den Testdatensatz\n",
    "predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Submission-Datei erstellen\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": np.arange(1, len(predictions) + 1),\n",
    "    \"Label\": predictions\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757a35b3-fe9e-4cc7-a958-84b908a2c3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission-Datei wurde erstellt: submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission.to_csv(\"submission1.csv\", index=False)\n",
    "\n",
    "print(\"Submission-Datei wurde erstellt: submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ccf2c1-56eb-4dc7-94c3-d76205c56eae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
